# Topic Ideas

- Compare JS reactive vs golang
- Benefits of using streams?
  - standard operators, iterations, flows
- Practice Make and explain Lexer example

# Agenda

- Introduction (10 minutes)
- Theory (30 minutes)
  - Programming Languages Intro
  - Lexer, Parser and so on

    - Programming Languages is 

      - alphabet
      - chain of symbols
      - subset of chains - language

      - How do we define a language?
        - all chains in a language
        - a language definition with set of rules, alphabet, formal definition

    - Compiler

        - a program that answers the question - if the test is part of language

    - Grammar
      - BNF (bacus-naur form)
      - G = (N,T,P,S)
        N - Non-terminals
        T - terminals (N&T == 0)
        P - procedures, producer (a->b, a is .., b is ..)
        S - start
      - producers are a "call" of producer rules
      - a languages is all end forms of applied producers
      - Equivivalent languages

        Example 1

        2.5. G = ({S, B, C}, {a, b, c}, P, S),  ={S→aSBC, S→aBC, CB→BC, aB→ab, bB→ bb, bC → bc, cC → cc},  L(G) = {anbncn|n > 0}.

        2.6. G = ({S},{0, 1}, {S → 0S1, S → 01},S)

        2.7 G = ({S, A},{0, 1}, {S → 0S, S → 0A, A → 1A, A → 1},S).  L(G) = {0n1m|n, m > 0}.

      - Types
        L0 - non limit (any)
        L1 - non reducing (a->b) (context-dependent)
        L2 - context free (A->b)
        L3 - right-sided

    - 

    - Lexer, Tokenizer

      > A token is just a chunk of meaningful code with a type and a string associated with it. Given a + b(c), the tokens would be:

      ```
      NAME "a"
      PLUS "+"
      NAME "b"
      LEFT_PAREN "("
      NAME "c"
      RIGHT_PAREN ")"
      ```

    - Parser

    > A parser is a software component that takes input data (frequently text) and builds a data structure – often some kind of parse tree, abstract syntax tree or other hierarchical structure, giving a structural representation of the input while checking for correct syntax. The parsing may be preceded or followed by other steps, or these may be combined into a single step. The parser is often preceded by a separate lexical analyser, which creates tokens from the sequence of input characters; alternatively, these can be combined in scannerless parsing. Parsers may be programmed by hand or may be automatically or semi-automatically generated by a parser generator. Parsing is complementary to templating, which produces formatted output. These may be applied to different domains, but often appear together, such as the scanf/printf pair, or the input (front end parsing) and output (back end code generation) stages of a compiler. https://en.wikipedia.org/wiki/Parsing

    > operator precedence. An alternative term for this is order of operations, which should make clearer what operator precedence describes: which priority do different operators have. The canonical example is this one, which we saw earlier
    > 5 + 5 * 10

    TODO https://ruslanspivak.com/lsbasi-part7/

    compare with wikipedia c implemenation 

    write in a pseudocode

    ```go
    // 1 + 2 * 3
    // -> {1, +, {2, *, 3}}
    // 
    // 1 * 2 + 3
    // -> {{1, *, 2}, + , 3}
    func (p *Parser) parseExpression(precedence int) ast.Expression {
      // first precedence LOWEST
      // second precedence SUM
      prefix := p.prefixParseFns[p.curToken.Type]
      // first parseIntegerLiteral 1
      // second parseIntegerLiteral 2
      if prefix == nil {
        p.noPrefixParseFnError(p.curToken.Type)
        return nil
      }
      leftExp := prefix()

      // second precedence SUM, SUM > LOWEST
      for !p.peekTokenIs(token.SEMICOLON) && precedence < p.peekPrecedence() {
        infix := p.infixParseFns[p.peekToken.Type]
        // parseInfixExpression +
        if infix == nil {
          return leftExp
        }

        p.nextToken()

        leftExp = infix(leftExp)
      }

      return leftExp
    }
    ```

    so it's a set of lookahead functions,

    ```go
    func (p *Parser) parsePrefixExpression() ast.Expression {
      expression := &ast.PrefixExpression{
        Token:    p.curToken,
        Operator: p.curToken.Literal,
      }

      p.nextToken()

      expression.Right = p.parseExpression(PREFIX)

      return expression
    }
    ```

    we need to find appropriate reactive implementations for them. probably there will be same scan with additional structures. And actually it looks like a good idea to addd intermediate observables inside temporary tokens

    the task requires recursion
    actually, let's do the recursion with state
    we'll push every valid item, and pop when it is over

    write in pseudocode

    CALCULATOR

    first step

```js
function expr() {
    let left = nud(next())
    while (!eof)
        left = led(left, next())
    return left
}

// LED(left, operator) = Tree(left, operator, right=next())
```

```
// todo change to expr(bp(operator))
right := nud(next)
it.left = led(it.left, *it.operator, right)
```

that just eats everything from left to right

second step

```js
function expr(rbp = 0) {
	let left = nud(next())
	while (bp(peek()) > rbp)
    left = led(left, next())
    // LED(left, operator) = Tree(left, operator, right=expr(bp(operator)))
	return left
}

```

current implementation

```go
accToken, isAccToken := acc.(interToken)
currentToken := elem.(token.Token)

// if acc is not defined, save current state and continue
if !isAccToken {
  accNode := &ast.Node{Token: currentToken}
  accToken.states = append(accToken.states, accNode)

  return accToken, nil
}

// if acc is prefixExpression of a first item in state
currentState := accToken.states[len(accToken.states)-1]
accToken.states = accToken.states[:len(accToken.states)-1]

prefix := p.prefixParseFns[currentState.Token.Type]
if prefix == nil {
  log.Err("No prefix parse function found for token", currentState.Token.Type)
  return nil, nil
}

newState := prefix(currentState)
newState.Token = currentToken
// save states back
accToken.states = append(accToken.states, newState)

return accToken, nil

// func (p *Parser) parseExpression(precedence int) ast.Node {
// 	prefix := p.prefixParseFns[p.curToken.Type]
// 	if prefix == nil {
// 		p.noPrefixParseFnError(p.curToken.Type)
// 		return nil
// 	}
// 	leftExp := prefix()
// 	for !p.peekTokenIs(token.SEMICOLON) && precedence < p.peekPrecedence() {
// 		infix := p.infixParseFns[p.peekToken.Type]
// 		if infix == nil {
// 			return leftExp
// 		}

// 		p.nextToken()

// 		leftExp = infix(leftExp)
// 	}

// 	return leftExp
// }

// .Map(func(_ context.Context, i interface{}) (interface{}, error) {
// 	log.Debug("parser", i)
// 	tok := i.(token.Token)
// 	prefix := p.prefixParseFns[tok.Type]
// 	if prefix == nil {
// 		log.Info("Could not find prefix for token", tok)
// 		return nil, nil
// 	}
// 	leftExp := prefix()
// 	return leftExp, nil
// })
```


  - jvm
- Code Review (20 minutes)
  - Go needed concepts - modules, goroutines, channels
  - ReactiveX, rxgo
    - Operators - filter, map, create, scan
    - How to filter with order?

```
>> 1+2
{INT 1}
{+ +}
{INT 2}
>> 1+2 
{+ +}
{INT 1}
{INT 2}
>> 1+2
{INT 1}
{+ +}
{INT 2}
```

    - Oh, btw logger
  

    - Different states

```go
func (l *Lexer) Tokens() rxgo.Observable {
  return rxgo.Merge([]rxgo.Observable{
    // operators
    // l.observable.
    // Filter(func(i interface{}) bool {
    //   var str = i.(string)

    //   sort.Strings(token.ALL_OPERATORS)
    //   var index = sort.SearchStrings(token.ALL_OPERATORS, str)

    //   return token.ALL_OPERATORS[index] == str
    // }).
    // Map(func(_ context.Context, i interface{})(interface{}, error) {
    //   var str = i.(string)
    //   ch := []byte(str)[0]
    //   var index = sort.SearchStrings(token.ALL_OPERATORS, str)

    //   var tok token.Token = newToken(token.TokenType(token.ALL_OPERATORS[index]), ch)
    //   return tok, nil
    // }),
    // numbers
    l.observable.
    // Filter(func(i interface{}) bool {
    //   var str = i.(string)
    //   ch := []byte(str)[0]

    //   return isNumber(ch)
    // }).
    DistinctUntilChanged(func(_ context.Context, i interface{}) (interface{}, error) {
      var str = i.(string)
      ch := []byte(str)[0]
      log.Info(str)
  
      return isNumber(ch), nil
    }).
    // Reduce(func(_ context.Context, acc interface{}, elem interface{}) (interface{}, error) {
    //   if acc == nil {
    //     return elem, nil
    //   }
    //   return acc.(string) + elem.(string), nil
    // }),
    // SumInt64()
    Map(func(_ context.Context, i interface{})(interface{}, error) {
      var str = i.(string)
      ch := []byte(str)[0]

      var tok token.Token = newToken(token.INT, ch)
      return tok, nil
    }),
  })
}
```

```bash
>> 11-00
distinct:  1
distinct:  11
distinct:  11-
map:  11-
map:  11-
distinct:  11-0
map:  11-0
{INT 11-}
distinct:  11-00
{INT 11-}
{INT 11-0}
>> 11-00
distinct:  1
distinct:  11
distinct:  11-
map:  11-
map:  11-
{INT 11-}
{INT 11-}
distinct:  11-0
distinct:  11-00
map:  11-00
{INT 11-00}
```

other problems and final flow with Filter, Scan, Filter (swap)

11=00

scan 1: save 1
scan 11: save 11
scan 11=: return 11, save =
scan =0: return =, save 0
scan 00: save 00
scan .: return 00

  - Explain language techniques

# TODO

- http://rigaux.org/language-study/syntax-across-languages/Mthmt.html

- change all lists to reactive collections?

- why to use observables?

- check syntax

```go
// type conversion
i.V.(string)
```

- check concept channels, goroutine

# Feedback

- Where do we go from here?
  - WebAssembly - try a compile target, explain WebAssembly basics
  - Programming languages - extending PizzaScript and the interpreter
  - More on Golang? 
  - More on ReactiveX operators?

# Summary

- Use appropiate tools
- First implement draft algorithm, than polish

- Learn lots of Go specifics
- Learn Rx operators
- Program

## Links

TODO https://dev.to/jrop/pratt-parsing

- [How to choose operator?](http://xgrommx.github.io/rx-book/content/which_operator_do_i_use/instance_operators.html)

TODO hand-written vs automatic parsers