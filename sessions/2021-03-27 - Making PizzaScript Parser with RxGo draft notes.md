# TODO

- [ ] Complete https://ruslanspivak.com/lsbasi-part3/

- [ ] Schedule twit - Amazing reading about interpreters and compilers https://ruslanspivak.com/lsbasi-part7/ @rspivak
- [ ] Schedule twit - Another tip from #PizzaScript ðŸ•project. Many resources mention compiler steps as streams. Reminding us about ReactiveX technology we've chosen.
- [ ] Schedule twit - #PizzaScript ðŸ•programming language appreciates your help, however can handle the thing itself.

# Topic

- Making PizzaScript Parser with RxGo

# Agenda

- Introduction (10 minutes)
  - Programming Languages Intro
  - Compilers
    - Lexer (scanner or tokenizer)

Check your understanding

- What is an interpreter?

> An interpreter is a program that executes other programs

- What is a compiler?
- Whatâ€™s the difference between an interpreter and a compiler?
- What is a token?
- What is the name of the process that breaks input apart into tokens?
- What is the part of the interpreter that does lexical analysis called?
- What are the other common names for that part of an interpreter or a compiler?

https://ruslanspivak.com/lsbasi-part1/

- What is a lexeme?
- What is the name of the process that finds the structure in the stream of tokens, or put differently, what is the name of the process that recognizes a certain phrase in that stream of tokens?
- What is the name of the part of the interpreter (compiler) that does parsing?

https://ruslanspivak.com/lsbasi-part2/

- todo Homogeneous AST :) vs Normalized Heterogeneous AST

> Homogeneous AST, on page 109 is as simple as you can get. It uses a single object type to represent every node in the tree. Homoge- neous nodes also have to represent specific children by position within a list rather than with named node fields. We call that a normalized child list.

> For example, we might want different node types for addition operator nodes and variable reference nodes. When building heterogeneous node types, itâ€™s common practice to track children with fields rather than lists

---

Usually, compilers act more in an "imperative" way, by controlling processed text and position. With `RxGo` and `Observable` pattern this concept changes from top to bottom. And here is the challenge. Now, a stream of asynchronous events is the compiler's input and handlers have to deal with it. We saw how it happened with lexer before. Instead of saving and incrementing the current position while reading text, we operate on given text chunks. We had to save the aggregated object. todo code.

- Parsers

    > A parser is a software component that takes input data (frequently text) and builds a data structure â€“ often some kind of parse tree, abstract syntax tree or other hierarchical structure, giving a structural representation of the input while checking for correct syntax. The parsing may be preceded or followed by other steps, or these may be combined into a single step. The parser is often preceded by a separate lexical analyser, which creates tokens from the sequence of input characters; alternatively, these can be combined in scannerless parsing. Parsers may be programmed by hand or may be automatically or semi-automatically generated by a parser generator. Parsing is complementary to templating, which produces formatted output. These may be applied to different domains, but often appear together, such as the scanf/printf pair, or the input (front end parsing) and output (back end code generation) stages of a compiler. https://en.wikipedia.org/wiki/Parsing

    > operator precedence. An alternative term for this is order of operations, which should make clearer what operator precedence describes: which priority do different operators have. The canonical example is this one, which we saw earlier
    > 5 + 5 * 10

    compare with wikipedia c implemenation 

    write in a pseudocode

    ```go
    // 1 + 2 * 3
    // -> {1, +, {2, *, 3}}
    // 
    // 1 * 2 + 3
    // -> {{1, *, 2}, + , 3}
    func (p *Parser) parseExpression(precedence int) ast.Expression {
      // first precedence LOWEST
      // second precedence SUM
      prefix := p.prefixParseFns[p.curToken.Type]
      // first parseIntegerLiteral 1
      // second parseIntegerLiteral 2
      if prefix == nil {
        p.noPrefixParseFnError(p.curToken.Type)
        return nil
      }
      leftExp := prefix()

      // second precedence SUM, SUM > LOWEST
      for !p.peekTokenIs(token.SEMICOLON) && precedence < p.peekPrecedence() {
        infix := p.infixParseFns[p.peekToken.Type]
        // parseInfixExpression +
        if infix == nil {
          return leftExp
        }

        p.nextToken()

        leftExp = infix(leftExp)
      }

      return leftExp
    }
    ```

    so it's a set of lookahead functions,

    ```go
    func (p *Parser) parsePrefixExpression() ast.Expression {
      expression := &ast.PrefixExpression{
        Token:    p.curToken,
        Operator: p.curToken.Literal,
      }

      p.nextToken()

      expression.Right = p.parseExpression(PREFIX)

      return expression
    }
    ```

    we need to find appropriate reactive implementations for them. probably there will be same scan with additional structures. And actually it looks like a good idea to addd intermediate observables inside temporary tokens

    the task requires recursion
    actually, let's do the recursion with state
    we'll push every valid item, and pop when it is over

    write in pseudocode

    CALCULATOR

    first step

```js
function expr() {
    let left = nud(next())
    while (!eof)
        left = led(left, next())
    return left
}

// LED(left, operator) = Tree(left, operator, right=next())
```

```
// todo change to expr(bp(operator))
right := nud(next)
it.left = led(it.left, *it.operator, right)
```

that just eats everything from left to right

second step

```js
function expr(rbp = 0) {
	let left = nud(next())
	while (bp(peek()) > rbp)
    left = led(left, next())
    // LED(left, operator) = Tree(left, operator, right=expr(bp(operator)))
	return left
}

```

current implementation

```go
accToken, isAccToken := acc.(interToken)
currentToken := elem.(token.Token)

// if acc is not defined, save current state and continue
if !isAccToken {
  accNode := &ast.Node{Token: currentToken}
  accToken.states = append(accToken.states, accNode)

  return accToken, nil
}

// if acc is prefixExpression of a first item in state
currentState := accToken.states[len(accToken.states)-1]
accToken.states = accToken.states[:len(accToken.states)-1]

prefix := p.prefixParseFns[currentState.Token.Type]
if prefix == nil {
  log.Err("No prefix parse function found for token", currentState.Token.Type)
  return nil, nil
}

newState := prefix(currentState)
newState.Token = currentToken
// save states back
accToken.states = append(accToken.states, newState)

return accToken, nil

// func (p *Parser) parseExpression(precedence int) ast.Node {
// 	prefix := p.prefixParseFns[p.curToken.Type]
// 	if prefix == nil {
// 		p.noPrefixParseFnError(p.curToken.Type)
// 		return nil
// 	}
// 	leftExp := prefix()
// 	for !p.peekTokenIs(token.SEMICOLON) && precedence < p.peekPrecedence() {
// 		infix := p.infixParseFns[p.peekToken.Type]
// 		if infix == nil {
// 			return leftExp
// 		}

// 		p.nextToken()

// 		leftExp = infix(leftExp)
// 	}

// 	return leftExp
// }

// .Map(func(_ context.Context, i interface{}) (interface{}, error) {
// 	log.Debug("parser", i)
// 	tok := i.(token.Token)
// 	prefix := p.prefixParseFns[tok.Type]
// 	if prefix == nil {
// 		log.Info("Could not find prefix for token", tok)
// 		return nil, nil
// 	}
// 	leftExp := prefix()
// 	return leftExp, nil
// })
```

- ReactiveX, rxgo
  - Benefits of using streams
    - standard operators, 
    - iterators, 
    - flows,
    - asyncronous,
    - immutable
  - Operators Overview - filter, map, create, scan

  > Does Scala have ReactiveX analogue?

- Code Review (20 minutes)
  - Oh, btw logger
  - Explain language techniques

# TODO

- http://rigaux.org/language-study/syntax-across-languages/Mthmt.html

- change all lists to reactive collections?

- why to use observables?

- check syntax

```go
// type conversion
i.V.(string)
```

- check concept channels, goroutine

# Feedback

- Where do we go from here?
  - WebAssembly - try a compile target, explain WebAssembly basics
  - Programming languages - extending PizzaScript and the interpreter
  - More on Golang? 
  - More on ReactiveX operators?

# Summary

- Use appropiate tools
- First implement draft algorithm, than polish

- Learn lots of Go specifics
- Learn Rx operators
- Program

## Links

TODO https://dev.to/jrop/pratt-parsing

- [How to choose operator?](http://xgrommx.github.io/rx-book/content/which_operator_do_i_use/instance_operators.html)

TODO hand-written vs automatic parsers

TODO check *ast.Node - * vs &